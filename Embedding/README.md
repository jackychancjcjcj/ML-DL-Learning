# Embedding（实体嵌入）的理解
`Embedding`是将离散变量序列化为连续变量的方法。一般可用于NLP的word embedding和类别数据的entity embedding。在数据挖掘场景下，当分类特征水平很高的时候，one-hot编码经常会带来维度爆炸的问题，并且会丢失类别间潜在的关联。  
* 实体嵌入可以用低维度的连续空间表示高维的离散空间，通过嵌入层处理。  
* 实体嵌入通过将分类属性放入网络的全连接层的输入单元中，后接几个单元数较输入层更少的隐藏层（连续型变量直接接入第一个隐藏层），经过神经网络训练后输出第一个隐藏层中分类变量关联的隐层单元，作为提取的特征，用于各种模型的输入。
## Embedding目的
* 在 embedding 空间中查找最近邻，这可以很好的用于根据用户的兴趣来进行推荐。  
* 作为监督性学习任务的输入。  
* 用于可视化不同离散变量之间的关系。  
## 优缺点
* 这种针对分类变量特征提取的方法对于提升预测准确率来说是很有效的，跟模型stacking一样有效。  
* 关于类别的embedding，一般比较常用的是item2vec的思路，就是用word2vec来处理多值离散特征，需要注意的是，只有类别之间存在关联性，比如特征A的类别是男，女，特征B的类别是包包，鞋子，剃须刀之类的，存在共现的情况才可以取使用word2vec的思路来做自监督的embedding  
* 当然这种方法不是很稳定，如果类别特征之间独立性较强，用word2vec的方式没什么作用。
